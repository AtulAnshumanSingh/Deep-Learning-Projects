{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoEncoder.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "t3eYVaEi0S-o",
        "colab_type": "code",
        "outputId": "afa7dcfd-cb63-4c72-91fa-74e9dfc139ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "def encoder(input, input_feature):\n",
        "    \n",
        "    with tf.name_scope(\"encoder\"):\n",
        "\n",
        "        with tf.name_scope(\"layer_1\"):\n",
        "            \n",
        "            input_features = input_feature\n",
        "            w = tf.get_variable('weights1', [input_features, 1000], initializer=tf.random_normal_initializer(stddev=(1.0/input_features)**0.5))\n",
        "            b = tf.get_variable('biases1', [1000],initializer=tf.constant_initializer(0.0))\n",
        "        \n",
        "            pool = tf.reshape(input, [-1, input_features])\n",
        "            fc1 = tf.nn.sigmoid(tf.matmul(pool, w) + b, name='relu')\n",
        "        \n",
        "        with tf.name_scope(\"layer_2\"):\n",
        "        \n",
        "            w2 = tf.get_variable('weights2', [1000, 500], initializer=tf.random_normal_initializer(stddev=(1.0/1000)**0.5))\n",
        "            b2 = tf.get_variable('biases2', [500],initializer=tf.constant_initializer(0.0))\n",
        "        \n",
        "            pool2 = tf.reshape(fc1, [-1, 1000])\n",
        "            fc2 = tf.nn.sigmoid(tf.matmul(pool2, w2) + b2, name='relu')\n",
        "        \n",
        "        with tf.name_scope(\"layer_3\"):\n",
        "        \n",
        "            w3 = tf.get_variable('weights3', [500, 250], initializer=tf.random_normal_initializer(stddev=(1.0/500)**0.5))\n",
        "            b3 = tf.get_variable('biases3', [250],initializer=tf.constant_initializer(0.0))\n",
        "        \n",
        "            pool3 = tf.reshape(fc2, [-1, 500])\n",
        "            fc3 = tf.nn.sigmoid(tf.matmul(pool3, w3) + b3, name='relu')\n",
        "            \n",
        "        with tf.name_scope(\"layer_4\"):\n",
        "        \n",
        "            w4 = tf.get_variable('weights4', [250, 2], initializer=tf.random_normal_initializer(stddev=(1.0/250)**0.5))\n",
        "            b4 = tf.get_variable('biases4', [2],initializer=tf.constant_initializer(0.0))\n",
        "        \n",
        "            pool4 = tf.reshape(fc3, [-1, 250])\n",
        "            fc4 = tf.nn.sigmoid(tf.matmul(pool4, w4) + b4, name='relu')\n",
        "    \n",
        "    return fc4\n",
        "\n",
        "def decoder(input, input_feature):\n",
        "    \n",
        "    with tf.name_scope(\"decoder\"):\n",
        "\n",
        "        with tf.name_scope(\"layer_1\"):\n",
        "            \n",
        "            input_features = input_feature\n",
        "            w = tf.get_variable('weights12', [input_features, 250], initializer=tf.random_normal_initializer(stddev=(1.0/2)**0.5))\n",
        "            b = tf.get_variable('biases12', [250],initializer=tf.constant_initializer(0.0))\n",
        "        \n",
        "            pool = tf.reshape(input, [-1, input_features])\n",
        "            fc11 = tf.nn.sigmoid(tf.matmul(pool, w) + b, name='relu')\n",
        "        \n",
        "        with tf.name_scope(\"layer_2\"):\n",
        "        \n",
        "            w2 = tf.get_variable('weights22', [250, 500], initializer=tf.random_normal_initializer(stddev=(1.0/250)**0.5))\n",
        "            b2 = tf.get_variable('biases22', [500],initializer=tf.constant_initializer(0.0))\n",
        "        \n",
        "            pool2 = tf.reshape(fc11, [-1, 250])\n",
        "            fc12 = tf.nn.sigmoid(tf.matmul(pool2, w2) + b2, name='relu')\n",
        "        \n",
        "        with tf.name_scope(\"layer_32\"):\n",
        "        \n",
        "            w3 = tf.get_variable('weights32', [500, 1000], initializer=tf.random_normal_initializer(stddev=(1.0/500)**0.5))\n",
        "            b3 = tf.get_variable('biases32', [1000],initializer=tf.constant_initializer(0.0))\n",
        "        \n",
        "            pool3 = tf.reshape(fc12, [-1, 500])\n",
        "            fc13 = tf.nn.sigmoid(tf.matmul(pool3, w3) + b3, name='relu')\n",
        "            \n",
        "        with tf.name_scope(\"layer_4\"):\n",
        "        \n",
        "            w4 = tf.get_variable('weights42', [1000, 784], initializer=tf.random_normal_initializer(stddev=(1.0/1000)**0.5))\n",
        "            b4 = tf.get_variable('biases42', [784],initializer=tf.constant_initializer(0.0))\n",
        "        \n",
        "            pool4 = tf.reshape(fc13, [-1, 1000])\n",
        "            fc14 = tf.nn.sigmoid(tf.matmul(pool4, w4) + b4, name='relu')\n",
        "    \n",
        "    return fc14\n",
        "\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, 784], name=\"X_placeholder\")\n",
        "\n",
        "model = encoder(X, 784)\n",
        "output = decoder(model, 2)\n",
        "\n",
        "\n",
        "l2 = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(output, X)),1))\n",
        "train_loss = tf.reduce_mean(l2)\n",
        "\n",
        "global_step = tf.Variable(0, name='global_step',trainable=False)\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=0.001,  name='Adam').minimize(train_loss, global_step=global_step)\n",
        "\n",
        "MNIST = input_data.read_data_sets(\"/data/mnist\", one_hot=True)\n",
        "\n",
        "BATCH_SIZE = 100\n",
        "training_epochs = 200\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    initial_step = global_step.eval()\n",
        "\n",
        "    n_batches = int(MNIST.train.num_examples / BATCH_SIZE)\n",
        "\n",
        "    total_loss = 0.0\n",
        "    for epoch in range(training_epochs):\n",
        "      total_loss = 0.0\n",
        "      for index in range(BATCH_SIZE):\n",
        "          X_batch, Y_batch = MNIST.train.next_batch(BATCH_SIZE)\n",
        "          _, out, loss_batch = sess.run([optimizer, output, train_loss],feed_dict={X: X_batch}) \n",
        "          total_loss += loss_batch\n",
        "      if epoch%10 == 0:\n",
        "        print(\"Total loss at epoch {}\".format(epoch),\" is {}\".format(total_loss/BATCH_SIZE))\n"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /data/mnist/train-images-idx3-ubyte.gz\n",
            "Extracting /data/mnist/train-labels-idx1-ubyte.gz\n",
            "Extracting /data/mnist/t10k-images-idx3-ubyte.gz\n",
            "Extracting /data/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Total loss at epoch 0  is 7.414696755409241\n",
            "Total loss at epoch 10  is 6.342852268218994\n",
            "Total loss at epoch 20  is 6.072218623161316\n",
            "Total loss at epoch 30  is 5.9323591709136965\n",
            "Total loss at epoch 40  is 5.8719602394104005\n",
            "Total loss at epoch 50  is 5.663709354400635\n",
            "Total loss at epoch 60  is 5.616005120277404\n",
            "Total loss at epoch 70  is 5.492730760574341\n",
            "Total loss at epoch 80  is 5.465679950714112\n",
            "Total loss at epoch 90  is 5.441252055168152\n",
            "Total loss at epoch 100  is 5.401034083366394\n",
            "Total loss at epoch 110  is 5.377362885475159\n",
            "Total loss at epoch 120  is 5.34897096157074\n",
            "Total loss at epoch 130  is 5.504457058906556\n",
            "Total loss at epoch 140  is 5.307646417617798\n",
            "Total loss at epoch 150  is 5.317719311714172\n",
            "Total loss at epoch 160  is 5.2618550062179565\n",
            "Total loss at epoch 170  is 5.292851691246033\n",
            "Total loss at epoch 180  is 5.237358593940735\n",
            "Total loss at epoch 190  is 5.210805335044861\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "63VC9sw89ShI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "68a0bd60-a15b-41e2-86e7-5913b39c20a8"
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(out[10].reshape(28,28))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f53741b0128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAcCAsAQAA8ISAAz+BwIA8uCifszhAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "qp9NZyCg4QP9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}